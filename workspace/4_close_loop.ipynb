{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice “closing the feedback loop”\n",
    "\n",
    "When there are no natural ground truth labels, we need to explicitly “close the feedback loop”:\n",
    "\n",
    "-   in order to evaluate how well our model does in production, versus in offline evaluation on a held-out test set,\n",
    "-   and also to get new “production data” on which to re-train the model when its performance degrades.\n",
    "\n",
    "For example, with this food type classifier, once it is deployed to “real” users:\n",
    "\n",
    "-   We could set aside a portion of production data for a human to label.\n",
    "-   We could set aside samples where the model has low confidence in its prediction, for a human to label. These extra-difficult samples are especially useful for re-training.\n",
    "-   We could allow users to give explicit feedback about whether the label assigned to their image is correct or not. This feedback may be sparse (some users won’t bother giving feedback even if the label is wrong) and noisy (some users may give incorrect feedback). We can get human annotators to label this data, too.\n",
    "-   We could allow users to explicitly label their images, by changing the label that is assigned by the classifier. This feedback may be sparse (some users won’t bother giving feedback even if the label is wrong) and noisy (some users may give incorrect feedback).\n",
    "\n",
    "We’re going to try out all of these options!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Architecture and Data Flow\n",
    "\n",
    "Here’s how all the components work together:\n",
    "\n",
    "1.  **Flask Service**: This is our web application that users interact with. It uploads images to MinIO and creates task JSON files.\n",
    "\n",
    "2.  **FastAPI Service**: This provides the machine learning prediction endpoint that the Flask app calls.\n",
    "\n",
    "3.  **MinIO Object Store**: This stores all our data:\n",
    "\n",
    "    -   Images are stored in the “production” bucket by class\n",
    "    -   JSON task files are stored in the “labelstudio/tasks/” directory\n",
    "    -   Labeled data will be stored in output locations configured in Label Studio\n",
    "\n",
    "4.  **Label Studio**: This is our annotation platform that:\n",
    "\n",
    "    -   Reads task JSON files from the “labelstudio/tasks/” directory in MinIO\n",
    "    -   Presents images to annotators\n",
    "    -   Saves completed annotations to output storage locations “labelstudio/output/” in MinIO\n",
    "\n",
    "Data flows like this: User → Flask → FastAPI → Flask → MinIO Source Storage Buckets → Label Studio → Annotated Data Buckets (Target Storage Buckets)\n",
    "\n",
    "Now, lets bring the system up by running the below cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing up system using Docker-compose\n",
    "remote.run('docker-compose -f /home/cc/eval-loop-chi/docker/docker-compose-feedback.yaml up -d')\n",
    "\n",
    "# Lets wait 30 seconds for it to get ready\n",
    "remote.run('sleep 15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post that, let’s run the script that sets up the necessary things in Label Studio 1. Creates three different projects for each specific task ( Random sampling, User Feedback, Low Confidence) with necessary details. 2. Sets up the labeling interface with the same configuration for all projects 3. Connects to MinIO S3 storage for both input (source) and output (target) data 3. Configures separate folders for each project’s data\n",
    "\n",
    "After running the next cell, go to {node-public-ip}:8080 and login with credentials and explore Label Studio. `username` : gourmetgramuser@gmail.com `password` : gourmetgrampassword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# Setting up Label Studio (Replace label_studio_container_id with the correct container id using docker ps )\n",
    "remote.run('docker exec label_studio_container_id python3 setup_label_studio.py')\n",
    "```\n",
    "\n",
    "### Set aside data for a human to label\n",
    "\n",
    "We are going to store the production images in a `production` bucket present in the minio object store.\n",
    "\n",
    "In order to do this, let’s modify the flask application.\n",
    "\n",
    "1.  Install s3fs package which we will use to interact with the Minio container\n",
    "\n",
    "``` bash\n",
    "pip install s3fs\n",
    "```\n",
    "\n",
    "1.  Use nano to modify app.py and insert the following 3 blocks of code\n",
    "\n",
    "``` python\n",
    "import s3fs\n",
    "import json\n",
    "import datetime\n",
    "import uuid\n",
    "#Include jsonify here\n",
    "from flask import Flask, redirect, url_for, request, render_template, jsonify\n",
    "# Initalize s3fs \n",
    "fs = s3fs.S3FileSystem(endpoint_url=\"http://minio:9000\",key=\"minioadmin\",secret=\"minioadmin\",use_ssl=False)\n",
    "\n",
    "classes = np.array([\"Bread\", \"Dairy product\", \"Dessert\", \"Egg\", \"Fried food\",\n",
    "    \"Meat\", \"Noodles/Pasta\", \"Rice\", \"Seafood\", \"Soup\",\n",
    "    \"Vegetable/Fruit\"])\n",
    "\n",
    "# Dictionary to track predictions\n",
    "current_predictions = {}\n",
    "```\n",
    "\n",
    "``` python\n",
    "# Function to store prediction data\n",
    "def store_prediction_in_tracking(prediction_data):\n",
    "    # Path to the JSON file in tracking bucket\n",
    "    object_path = \"tracking/production.json\"\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    try:\n",
    "        if fs.exists(object_path):\n",
    "            # Read existing data\n",
    "            with fs.open(object_path, 'r') as f:\n",
    "                existing_data = json.load(f)\n",
    "        else:\n",
    "            # Start with empty list if file doesn't exist\n",
    "            existing_data = []\n",
    "            \n",
    "        # Add new prediction data with timestamp\n",
    "        prediction_data[\"timestamp\"] = datetime.datetime.now().isoformat()\n",
    "        existing_data.append(prediction_data)\n",
    "        \n",
    "        # Write updated data back to file\n",
    "        with fs.open(object_path, 'w') as f:\n",
    "            json.dump(existing_data, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error storing prediction in tracking: {e}\")\n",
    "```\n",
    "\n",
    "Change the predict function to this\n",
    "\n",
    "``` python\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload():\n",
    "    preds = None\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        filename = secure_filename(f.filename)\n",
    "        f.save(os.path.join(app.instance_path, 'uploads', filename))\n",
    "        img_path = os.path.join(app.instance_path, 'uploads', filename)\n",
    "       \n",
    "        preds, probs = request_fastapi(img_path)\n",
    "        if preds:\n",
    "            pred_index = np.where(classes == preds)[0][0]\n",
    "            \n",
    "            # Format the class directory name with the index\n",
    "            class_dir = f\"class_{pred_index:02d}\"\n",
    "            \n",
    "            # Create the S3 path\n",
    "            bucket_name = \"production\"\n",
    "            s3_path = f\"{bucket_name}/{class_dir}/{secure_filename(f.filename)}\"\n",
    "            \n",
    "            # Upload the file to S3/MinIO\n",
    "            fs.put(img_path, s3_path)\n",
    "\n",
    "            prediction_id = str(uuid.uuid4())\n",
    "\n",
    "            current_predictions[prediction_id] = {\n",
    "                \"prediction_id\": prediction_id,\n",
    "                \"filename\": filename,\n",
    "                \"prediction\": preds,\n",
    "                \"confidence\": probs,\n",
    "                \"image_url\": f\"http://localhost:9000/production/{class_dir}/{filename}\",\n",
    "                \"class_dir\": class_dir,\n",
    "                \"sampled\" : False\n",
    "            }\n",
    "\n",
    "            # Store prediction in tracking\n",
    "            store_prediction_in_tracking(current_predictions[prediction_id])\n",
    "            \n",
    "            return f'<button type=\"button\" class=\"btn btn-info btn-sm\">{preds}</button>'\n",
    "    \n",
    "    return '<a href=\"#\" class=\"badge badge-warning\">Warning</a>'\n",
    "```\n",
    "\n",
    "Execute the below cell to reload the Flask application with our new code. Now, every image that is predicted by the Flask application is stored in the `production` bucket in the respective class folder. You can test it by predicting an image and checking it in the Minio Object Store at {node-public-ip}:9001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restarting the Flask container with the updated frontend and app.py\n",
    "remote.run(\"docker-compose -f /home/cc/eval-loop-chi/docker/docker-compose-feedback.yaml restart flask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a cron job to run random sampling once per day\n",
    "remote.run(\"echo '0 0 * * * docker exec label-studio python3 /label-studio/random_sampling.py' | crontab -\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set aside samples for which model has low confidence\n",
    "\n",
    "Low confidence means the model is unsure about the classification for a given image. These images which the model found difficult to predict are especially useful for re-training.\n",
    "\n",
    "Lets modify our Flask application so that the low confidence images are sent to human annotators for review and the annotated images are used for retraining later on.\n",
    "\n",
    "1.  Now, we define a new function `create_low_confidence_task` that creates a task for low confidence images in Label Studio and a dictionary `current_predictions` to keep track of prediction\n",
    "\n",
    "``` python\n",
    "\n",
    "def create_low_confidence_task(image_url, predicted_class, confidence, filename):\n",
    "    # Create unique task ID\n",
    "    task_id = str(uuid.uuid4())\n",
    "   \n",
    "    # Create task data\n",
    "    task_data = {\n",
    "        \"data\": {\n",
    "            \"image\": image_url,\n",
    "            \"ml_prediction\": predicted_class,\n",
    "            \"confidence\": confidence,\n",
    "            \"user_feedback\": \"low_confidence\",\n",
    "            \"source\": \"low_confidence\",\n",
    "            \"timestamp\": datetime.datetime.now().isoformat()\n",
    "        }\n",
    "    }\n",
    "   \n",
    "    # Create JSON file in memory\n",
    "    task_json = json.dumps(task_data, indent=2)\n",
    "   \n",
    "    # Define the object path\n",
    "    object_path = f\"labelstudio/tasks/lowconfidence/task_{task_id}.json\"\n",
    "   \n",
    "    # Upload JSON using s3fs\n",
    "    with fs.open(object_path, 'w') as f:\n",
    "        f.write(task_json)\n",
    "   \n",
    "    return task_id\n",
    "```\n",
    "\n",
    "1.  We will call this function when the confidence of predicted image goes below a pre-defined threshold\n",
    "\n",
    "``` python\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        filename = secure_filename(f.filename)\n",
    "        img_path = os.path.join(app.instance_path, 'uploads', filename)\n",
    "        f.save(img_path)\n",
    "       \n",
    "        preds, probs = request_fastapi(img_path)\n",
    "        if preds:\n",
    "            pred_index = np.where(classes == preds)[0][0]\n",
    "            \n",
    "            # Format the class directory name with the index\n",
    "            class_dir = f\"class_{pred_index:02d}\"\n",
    "            \n",
    "            # Create the S3 path\n",
    "            bucket_name = \"production\"\n",
    "            s3_path = f\"{bucket_name}/{class_dir}/{filename}\"\n",
    "            \n",
    "            # Upload the file to S3/MinIO\n",
    "            fs.put(img_path, s3_path)\n",
    "\n",
    "            prediction_id = str(uuid.uuid4())\n",
    "            current_predictions[prediction_id] = {\n",
    "                \"prediction_id\": prediction_id,\n",
    "                \"filename\": filename,\n",
    "                \"prediction\": preds,\n",
    "                \"confidence\": probs,\n",
    "                \"image_url\": f\"http://localhost:9000/production/{class_dir}/{filename}\",\n",
    "                \"class_dir\": class_dir,\n",
    "                \"sampled\" : False\n",
    "            }\n",
    "\n",
    "            store_prediction_in_tracking(current_predictions[prediction_id])\n",
    "\n",
    "            confidence_threshold = 0.7\n",
    "\n",
    "            if probs < confidence_threshold:\n",
    "                create_low_confidence_task(\n",
    "                    image_url=current_predictions[prediction_id][\"image_url\"],\n",
    "                    predicted_class=preds,\n",
    "                    confidence=probs,\n",
    "                    filename=filename\n",
    "                )\n",
    "            \n",
    "            return f'<button type=\"button\" class=\"btn btn-info btn-sm\">{preds}</button>'\n",
    "    \n",
    "    return '<a href=\"#\" class=\"badge badge-warning\">Warning</a>'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restarting the Flask container with the updated app.py\n",
    "remote.run(\"docker-compose -f /home/cc/eval-loop-chi/docker/docker-compose-feedback.yaml restart flask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a job to process the low confidence input jsons into Label Studio (Replace placeholder label-studio with actual container ID)\n",
    "remote.run(\"(crontab -l 2>/dev/null; echo '0 * * * * docker exec label-studio python3 /label-studio/sync_script.py 1') | crontab -\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get explicit feedback from users\n",
    "\n",
    "Now, lets look towards the user whether they think the prediction given is correct or not. This feedback may be sparse (some users won’t bother giving feedback even if the label is wrong) and noisy (some users may give incorrect feedback). We can get human annotators to label this data, too.\n",
    "\n",
    "1.  Just like the previous stage, we will include a new function create_user_feedback_task which creates tasks in Label Studio based on negative user feedback\n",
    "\n",
    "``` python\n",
    "def create_user_feedback_task(image_url, predicted_class, confidence, filename):\n",
    "    # Create unique task ID\n",
    "    task_id = str(uuid.uuid4())\n",
    "   \n",
    "    # Create task data\n",
    "    task_data = {\n",
    "        \"data\": {\n",
    "            \"image\": image_url,\n",
    "            \"ml_prediction\": predicted_class,\n",
    "            \"confidence\": confidence,\n",
    "            \"user_feedback\": \"incorrect\",\n",
    "            \"source\": \"user_feedback\",\n",
    "            \"timestamp\": datetime.datetime.now().isoformat()\n",
    "        }\n",
    "    }\n",
    "   \n",
    "    # Create JSON file in memory\n",
    "    task_json = json.dumps(task_data, indent=2)\n",
    "   \n",
    "    # Define the object path\n",
    "    object_path = f\"labelstudio/tasks/userfeedback/task_{task_id}.json\"\n",
    "   \n",
    "    # Upload JSON using s3fs\n",
    "    with fs.open(object_path, 'w') as f:\n",
    "        f.write(task_json)\n",
    "   \n",
    "    return task_id\n",
    "```\n",
    "\n",
    "1.  We will update the predict function to include a feedback button in the response\n",
    "\n",
    "``` python\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        filename = secure_filename(f.filename)\n",
    "        img_path = os.path.join(app.instance_path, 'uploads', filename)\n",
    "        f.save(img_path)\n",
    "       \n",
    "        preds, probs = request_fastapi(img_path)\n",
    "        if preds:\n",
    "            pred_index = np.where(classes == preds)[0][0]\n",
    "            \n",
    "            # Format the class directory name with the index\n",
    "            class_dir = f\"class_{pred_index:02d}\"\n",
    "            \n",
    "            # Create the S3 path\n",
    "            bucket_name = \"production\"\n",
    "            s3_path = f\"{bucket_name}/{class_dir}/{filename}\"\n",
    "            \n",
    "            # Upload the file to S3/MinIO\n",
    "            fs.put(img_path, s3_path)\n",
    "\n",
    "            # Store this prediction for feedback\n",
    "            prediction_id = str(uuid.uuid4())\n",
    "            current_predictions[prediction_id] = {\n",
    "                \"prediction_id\": prediction_id,\n",
    "                \"filename\": filename,\n",
    "                \"prediction\": preds,\n",
    "                \"confidence\": probs,\n",
    "                \"image_url\": f\"http://localhost:9000/production/{class_dir}/{filename}\",\n",
    "                \"class_dir\": class_dir,\n",
    "                \"sampled\" : False\n",
    "            }\n",
    "\n",
    "            store_prediction_in_tracking(current_predictions[prediction_id])\n",
    "            \n",
    "            # Return the result with a flag icon for incorrect label feedback\n",
    "            result_html = f'''\n",
    "            <div style=\"display: flex; align-items: center; margin-top: 10px;\">\n",
    "                <button type=\"button\" class=\"btn btn-info btn-sm\">{preds}</button>\n",
    "                <button class=\"btn btn-sm feedback-btn\" data-prediction-id=\"{prediction_id}\" \n",
    "                        data-bs-toggle=\"tooltip\" data-bs-placement=\"top\" title=\"Flag incorrect label\"\n",
    "                        style=\"background: none; border: none; color: #dc3545; padding: 2px 0 0 8px; margin-left: 5px;\">\n",
    "                    <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"16\" height=\"16\" fill=\"currentColor\" class=\"bi bi-flag\" viewBox=\"0 0 16 16\">\n",
    "                        <path d=\"M14.778.085A.5.5 0 0 1 15 .5V8a.5.5 0 0 1-.314.464L14.5 8l.186.464-.003.001-.006.003-.023.009a12.435 12.435 0 0 1-.397.15c-.264.095-.631.223-1.047.35-.816.252-1.879.523-2.71.523-.847 0-1.548-.28-2.158-.525l-.028-.01C7.68 8.71 7.14 8.5 6.5 8.5c-.7 0-1.638.23-2.437.477A19.626 19.626 0 0 0 3 9.342V15.5a.5.5 0 0 1-1 0V.5a.5.5 0 0 1 1 0v.282c.226-.079.496-.17.79-.26C4.606.272 5.67 0 6.5 0c.84 0 1.524.277 2.121.519l.043.018C9.286.788 9.828 1 10.5 1c.7 0 1.638-.23 2.437-.477a19.587 19.587 0 0 0 1.349-.476l.019-.007.004-.002h.001\"/>\n",
    "                    </svg>\n",
    "                </button>\n",
    "            </div>\n",
    "            '''\n",
    "            \n",
    "            return result_html\n",
    "    \n",
    "    return '<a href=\"#\" class=\"badge badge-warning\">Warning</a>'\n",
    "```\n",
    "\n",
    "1.  A /feedback endpoint and respective feedback function that handles user feedback\n",
    "\n",
    "``` python\n",
    "@app.route('/feedback', methods=['POST'])\n",
    "def feedback():\n",
    "    \"\"\"Handle user feedback about predictions\"\"\"\n",
    "    data = request.json\n",
    "    prediction_id = data.get('prediction_id')\n",
    "    \n",
    "    # Get the prediction data\n",
    "    pred_data = current_predictions[prediction_id]\n",
    "    \n",
    "    # Create user feedback task\n",
    "    task_id = create_user_feedback_task(\n",
    "        image_url=pred_data[\"image_url\"],\n",
    "        predicted_class=pred_data[\"prediction\"],\n",
    "        confidence=pred_data[\"confidence\"],\n",
    "        filename=pred_data[\"filename\"]\n",
    "    )\n",
    "    \n",
    "    # Return response\n",
    "    return jsonify({\n",
    "        \"success\": True,\n",
    "        \"message\": \"Thank you for your feedback!\"\n",
    "    })\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying front end files into our flask container to update the UI to include feedback\n",
    "remote.run(\"docker cp /home/cc/eval-loop-chi/frontend/feedback_v1/templates/index.html flask:/app/templates/index.html\")\n",
    "remote.run(\"docker cp /home/cc/eval-loop-chi/frontend/feedback_v1/templates/base.html flask:/app/templates/base.html\")\n",
    "\n",
    "remote.run(\"docker cp /home/cc/eval-loop-chi/frontend/feedback_v1/static/js/main.js flask:/app/static/js/main.js\")\n",
    "remote.run(\"docker cp /home/cc/eval-loop-chi/frontend/feedback_v1/static/css/main.css flask:/app/static/css/main.css\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restarting the Flask container with the updated frontend and app.py\n",
    "remote.run(\"docker-compose -f /home/cc/eval-loop-chi/docker/docker-compose-feedback.yaml restart flask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a job to process the low confidence input jsons into Label Studio (Replace placeholder with actual container ID)\n",
    "remote.run(\"(crontab -l 2>/dev/null; echo '0 * * * * docker exec label-studio python3 /label-studio/sync_script.py 2') | crontab -\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, go to the Flask frontend and you can see that the UI has a feedback button right of the prediction. Whenever user clicks on the Flag icon, a task json is sent to the input storage associated with ‘User Feedback’ Project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get explicit labels from users\n",
    "\n",
    ":::"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python"
  }
 }
}
