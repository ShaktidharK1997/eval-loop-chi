{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice “closing the feedback loop”\n",
    "\n",
    "When there are no natural ground truth labels, we need to explicitly “close the feedback loop”:\n",
    "\n",
    "-   in order to evaluate how well our model does in production, versus in offline evaluation on a held-out test set,\n",
    "-   and also to get new “production data” on which to re-train the model when its performance degrades.\n",
    "\n",
    "For example, with this food type classifier, once it is deployed to “real” users:\n",
    "\n",
    "-   We could set aside a portion of production data for a human to label.\n",
    "-   We could set aside samples where the model has low confidence in its prediction, for a human to label. These extra-difficult samples are especially useful for re-training.\n",
    "-   We could allow users to give explicit feedback about whether the label assigned to their image is correct or not. This feedback may be sparse (some users won’t bother giving feedback even if the label is wrong) and noisy (some users may give incorrect feedback). We can get human annotators to label this data, too.\n",
    "-   We could allow users to explicitly label their images, by changing the label that is assigned by the classifier. This feedback may be sparse (some users won’t bother giving feedback even if the label is wrong) and noisy (some users may give incorrect feedback).\n",
    "\n",
    "We’re going to try out all of these options!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Architecture and Data Flow\n",
    "\n",
    "Here’s how all the components work together:\n",
    "\n",
    "1.  **Flask Service**: This is our web application that users interact with. It uploads images to MinIO and creates task JSON files.\n",
    "\n",
    "2.  **FastAPI Service**: This provides the machine learning prediction endpoint that the Flask app calls.\n",
    "\n",
    "3.  **MinIO Object Store**: This stores all our data:\n",
    "\n",
    "    -   Images are stored in the “production” bucket by class\n",
    "    -   JSON task files are stored in the “labelstudio/tasks/” directory\n",
    "    -   JSON output files are stored in the “labelstudio/tasks/” directory\n",
    "    -   Labeled data will be stored in output locations configured in Label Studio\n",
    "\n",
    "4.  **Label Studio**: This is our annotation platform that:\n",
    "\n",
    "    -   Reads task JSON files from the “labelstudio/tasks/” directory\n",
    "    -   Presents images to annotators\n",
    "    -   Saves completed annotations to output storage locations “labelstudio/output/” in MinIO\n",
    "\n",
    "Data flows like this:\n",
    "\n",
    "`User → Flask → FastAPI → Flask → Source Storage (labelstudio/tasks/) → Label Studio → Target Storage (labelstudio/output/)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Label Studio for Annotation\n",
    "\n",
    "Let’s set up Label Studio, our tool for managing human annotations of images.\n",
    "\n",
    "Inside the SSH session,\n",
    "\n",
    "First, find your Label Studio container ID:\n",
    "\n",
    "``` bash\n",
    "docker ps | grep label\n",
    "```\n",
    "\n",
    "Run the below command :\n",
    "\n",
    "``` bash\n",
    "# Setting up Label Studio (Replace label_studio_container_id with the correct container id using docker ps )\n",
    "docker exec <label_studio_container_id> python3 setup_label_studio.py\n",
    "```\n",
    "\n",
    "This script:\n",
    "\n",
    "-   Creates three projects (Random Sampling, Low Confidence, User Feedback)\n",
    "-   Configures the labeling interface for food classification\n",
    "-   Connects to MinIO for source and target storage\n",
    "-   Sets up separate directories for each project’s data\n",
    "\n",
    "Access Label Studio UI: Visit http://{node-public-ip}:8080 and login with\n",
    "\n",
    "-   Username: gourmetgramuser@gmail.com\n",
    "-   Password: gourmetgrampassword\n",
    "-   Go into each project and check the sample task created\n",
    "-   Go into project settings\n",
    "    -   Check the Labelling interface tab\n",
    "    -   Check the Cloud Storage tab to see how the project connects to Source Storage and Target Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set aside data for a human to label\n",
    "\n",
    "We are going to store the images user provide in the `Production` bucket in MinIO Object store.\n",
    "\n",
    "In order to do this, let’s modify the flask application.\n",
    "\n",
    "Inside the SSH session :\n",
    "\n",
    "1.  Add `s3fs` to requirements.txt in the gourmetgram folder\n",
    "\n",
    "``` bash\n",
    "nano /home/cc/eval-loop-chi/gourmetgram/requirements.txt\n",
    "```\n",
    "\n",
    "1.  Copy functions folder into gourmetgram folder\n",
    "\n",
    "``` bash\n",
    "cp -r /home/cc/eval-loop-chi/functions /home/cc/eval-loop-chi/gourmetgram/functions\n",
    "```\n",
    "\n",
    "1.  Modify the contents of app.py in gourmetgram folder using below command.\n",
    "\n",
    "``` bash\n",
    "nano /home/cc/eval-loop-chi/gourmetgram/app.py\n",
    "```\n",
    "\n",
    "In app.py,\n",
    "\n",
    "Add these imports at the top of the file:\n",
    "\n",
    "``` python\n",
    "import s3fs\n",
    "import json\n",
    "import datetime\n",
    "import uuid\n",
    "#Include jsonify here\n",
    "from flask import Flask, redirect, url_for, request, render_template, jsonify\n",
    "from functions.storage import store_prediction_in_tracking\n",
    "```\n",
    "\n",
    "Initialize S3 Filesystem and a dictionary to store predictions:\n",
    "\n",
    "``` python\n",
    "# Initalize s3fs \n",
    "fs = s3fs.S3FileSystem(endpoint_url=\"http://minio:9000\",key=\"minioadmin\",secret=\"minioadmin\",use_ssl=False)\n",
    "\n",
    "classes = np.array([\"Bread\", \"Dairy product\", \"Dessert\", \"Egg\", \"Fried food\",\n",
    "    \"Meat\", \"Noodles/Pasta\", \"Rice\", \"Seafood\", \"Soup\",\n",
    "    \"Vegetable/Fruit\"])\n",
    "\n",
    "# Dictionary to store predictions\n",
    "current_predictions = {}\n",
    "```\n",
    "\n",
    "Update the upload() function to save images and prediction details :\n",
    "\n",
    "``` python\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload():\n",
    "    preds = None\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        filename = secure_filename(f.filename)\n",
    "        f.save(os.path.join(app.instance_path, 'uploads', filename))\n",
    "        img_path = os.path.join(app.instance_path, 'uploads', filename)\n",
    "       \n",
    "        preds, probs = request_fastapi(img_path)\n",
    "        if preds:\n",
    "            pred_index = np.where(classes == preds)[0][0]\n",
    "            \n",
    "            # Format the class directory name with the index\n",
    "            class_dir = f\"class_{pred_index:02d}\"\n",
    "            \n",
    "            # Create the S3 path\n",
    "            bucket_name = \"production\"\n",
    "            s3_path = f\"{bucket_name}/{class_dir}/{secure_filename(f.filename)}\"\n",
    "            \n",
    "            # Upload the file to S3/MinIO\n",
    "            fs.put(img_path, s3_path)\n",
    "\n",
    "            prediction_id = str(uuid.uuid4())\n",
    "\n",
    "            current_predictions[prediction_id] = {\n",
    "                \"prediction_id\": prediction_id,\n",
    "                \"filename\": filename,\n",
    "                \"prediction\": preds,\n",
    "                \"confidence\": probs,\n",
    "                \"image_url\": f\"http://localhost:9000/production/{class_dir}/{filename}\",\n",
    "                \"class_dir\": class_dir,\n",
    "                \"sampled\" : False\n",
    "            }\n",
    "\n",
    "            # Store prediction in tracking\n",
    "            store_prediction_in_tracking(fs, current_predictions[prediction_id])\n",
    "            \n",
    "            return f'<button type=\"button\" class=\"btn btn-info btn-sm\">{preds}</button>'\n",
    "    \n",
    "    return '<a href=\"#\" class=\"badge badge-warning\">Warning</a>'\n",
    "```\n",
    "\n",
    "Rebuild the Flask Container:\n",
    "\n",
    "``` bash\n",
    "# Rebuild the Flask container with the updated app.py\n",
    "docker-compose -f /home/cc/eval-loop-chi/docker/docker-compose-feedback.yaml up flask --build\n",
    "```\n",
    "\n",
    "Our first feedback loop method randomly selects production images for human annotation. Let’s set up a hourly cron job for random sampling and run it on demand once:\n",
    "\n",
    "``` bash\n",
    "# Set up a cron job to run random sampling once a day\n",
    "echo '0 0 * * * docker exec <label_studio_container_id> python3 /label-studio/random_sampling.py' | crontab -\n",
    "```\n",
    "\n",
    "``` bash\n",
    "docker exec <label_studio_container_id> python3 /label-studio/random_sampling.py' | crontab -\n",
    "```\n",
    "\n",
    "This cron job:\n",
    "\n",
    "-   Runs once per day\n",
    "-   Randomly selects unsampled images from the production bucket\n",
    "-   Creates task JSONs in the “labelstudio/tasks/randomsampling” folder\n",
    "\n",
    "Set up an daily cron job to sync with Label Studio and run it on demand once:\n",
    "\n",
    "``` bash\n",
    "(crontab -l 2>/dev/null; echo '0 0 * * * docker exec <label_studio_container_id> python3 /label-studio/sync_script.py 1') | crontab -\n",
    "```\n",
    "\n",
    "``` bash\n",
    "docker exec <label_studio_container_id> python3 /label-studio/sync_script.py 1\n",
    "```\n",
    "\n",
    "#### Testing the Feedback Loop\n",
    "\n",
    "1.  Go to http://{public-node-ip}:5000\n",
    "2.  Upload food-11 images images present in /data/food11 folder\n",
    "3.  Wait for random sampling script to run and Label Studio to Sync and Go to http://{public-node-ip}:8080 and login to see the tasks created by random sampling.\n",
    "4.  Complete the random sampling tasks and provide your prediction for the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set aside samples for which model has low confidence\n",
    "\n",
    "Our second method identifies images where the model has low confidence in its prediction, making them valuable for retraining.\n",
    "\n",
    "Use the below command to modify app.py :\n",
    "\n",
    "``` bash\n",
    "nano /home/cc/eval-loop-chi/gourmetgram/app.py\n",
    "```\n",
    "\n",
    "1.  Import Task Creation Function for low confidence tasks\n",
    "\n",
    "Add this import to app.py:\n",
    "\n",
    "``` python\n",
    "from functions.feedback_tasks import create_low_confidence_task\n",
    "```\n",
    "\n",
    "1.  Update the upload() function in app.py to identify and send low confidence predictions for review based on a predefined threshold:\n",
    "\n",
    "``` python\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        filename = secure_filename(f.filename)\n",
    "        img_path = os.path.join(app.instance_path, 'uploads', filename)\n",
    "        f.save(img_path)\n",
    "       \n",
    "        preds, probs = request_fastapi(img_path)\n",
    "        if preds:\n",
    "            pred_index = np.where(classes == preds)[0][0]\n",
    "            \n",
    "            # Format the class directory name with the index\n",
    "            class_dir = f\"class_{pred_index:02d}\"\n",
    "            \n",
    "            # Create the S3 path\n",
    "            bucket_name = \"production\"\n",
    "            s3_path = f\"{bucket_name}/{class_dir}/{filename}\"\n",
    "            \n",
    "            # Upload the file to S3/MinIO\n",
    "            fs.put(img_path, s3_path)\n",
    "\n",
    "            prediction_id = str(uuid.uuid4())\n",
    "            current_predictions[prediction_id] = {\n",
    "                \"prediction_id\": prediction_id,\n",
    "                \"filename\": filename,\n",
    "                \"prediction\": preds,\n",
    "                \"confidence\": probs,\n",
    "                \"image_url\": f\"http://localhost:9000/production/{class_dir}/{filename}\",\n",
    "                \"class_dir\": class_dir,\n",
    "                \"sampled\" : False\n",
    "            }\n",
    "\n",
    "            store_prediction_in_tracking(fs, current_predictions[prediction_id])\n",
    "\n",
    "            confidence_threshold = 0.7\n",
    "\n",
    "            if probs < confidence_threshold:\n",
    "                create_low_confidence_task(\n",
    "                    fs,\n",
    "                    image_url=current_predictions[prediction_id][\"image_url\"],\n",
    "                    predicted_class=preds,\n",
    "                    confidence=probs,\n",
    "                    filename=filename\n",
    "                )\n",
    "            \n",
    "            return f'<button type=\"button\" class=\"btn btn-info btn-sm\">{preds}</button>'\n",
    "    \n",
    "    return '<a href=\"#\" class=\"badge badge-warning\">Warning</a>'\n",
    "```\n",
    "\n",
    "1.  Rebuild the Flask container\n",
    "\n",
    "``` bash\n",
    "# Rebuild the Flask container with the updated app.py\n",
    "docker-compose -f /home/cc/eval-loop-chi/docker/docker-compose-feedback.yaml up flask --build\n",
    "```\n",
    "\n",
    "1.  Setup hourly job to sync Label Studio and run it once on demand\n",
    "\n",
    "``` bash\n",
    "# Setting up a job to process the low confidence input jsons into Label Studio (Replace placeholder label-studio with actual container ID)\n",
    "(crontab -l 2>/dev/null; echo '0 * * * * docker exec <label_studio_container_id> python3 /label-studio/sync_script.py 2') | crontab -\n",
    "```\n",
    "\n",
    "``` bash\n",
    "docker exec <label_studio_container_id> python3 /label-studio/sync_script.py 2\n",
    "```\n",
    "\n",
    "#### Testing the Feedback Loop\n",
    "\n",
    "1.  Go to http://{public-node-ip}:5000.\n",
    "2.  Upload ambiguous images images present in /lowconfidence folder in data.\n",
    "3.  Wait for Label Studio to Sync and Go to http://{public-node-ip}:8080 and login to see the tasks created by low confidence predictions.\n",
    "4.  Complete the low confidence tasks by giving your prediction for the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get explicit feedback from users\n",
    "\n",
    "Our third method enables users to provide feedback when they think the model’s prediction is incorrect. This feedback may be sparse (some users won’t bother giving feedback even if the label is wrong) and noisy (some users may give incorrect feedback). We can get human annotators to label this data, too.\n",
    "\n",
    "Use the below command to modify app.py :\n",
    "\n",
    "``` bash\n",
    "nano /home/cc/eval-loop-chi/gourmetgram/app.py\n",
    "```\n",
    "\n",
    "1.  Import Task Creation Function for user feedback tasks and add the flag icon SVG\n",
    "\n",
    "``` python\n",
    "from functions.feedback_tasks import create_user_feedback_task\n",
    "```\n",
    "\n",
    "1.  Update Upload Function to Include Feedback Button\n",
    "\n",
    "``` python\n",
    "with open('./images/flag-icon.svg', 'r') as f:\n",
    "    FLAG_SVG = f.read()\n",
    "\n",
    "@app.route('/predict', methods=['GET', 'POST'])\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        filename = secure_filename(f.filename)\n",
    "        img_path = os.path.join(app.instance_path, 'uploads', filename)\n",
    "        f.save(img_path)\n",
    "       \n",
    "        preds, probs = request_fastapi(img_path)\n",
    "        if preds:\n",
    "            pred_index = np.where(classes == preds)[0][0]\n",
    "            \n",
    "            # Format the class directory name with the index\n",
    "            class_dir = f\"class_{pred_index:02d}\"\n",
    "            \n",
    "            # Create the S3 path\n",
    "            bucket_name = \"production\"\n",
    "            s3_path = f\"{bucket_name}/{class_dir}/{filename}\"\n",
    "            \n",
    "            # Upload the file to S3/MinIO\n",
    "            fs.put(img_path, s3_path)\n",
    "\n",
    "            # Store this prediction for feedback\n",
    "            prediction_id = str(uuid.uuid4())\n",
    "            current_predictions[prediction_id] = {\n",
    "                \"prediction_id\": prediction_id,\n",
    "                \"filename\": filename,\n",
    "                \"prediction\": preds,\n",
    "                \"confidence\": probs,\n",
    "                \"image_url\": f\"http://localhost:9000/production/{class_dir}/{filename}\",\n",
    "                \"class_dir\": class_dir,\n",
    "                \"sampled\" : False\n",
    "            }\n",
    "\n",
    "            store_prediction_in_tracking(fs,current_predictions[prediction_id])\n",
    "            \n",
    "            # Return the result with a flag icon for incorrect label feedback\n",
    "            result_html = f'''\n",
    "            <div style=\"display: flex; align-items: center; margin-top: 10px;\">\n",
    "                <button type=\"button\" class=\"btn btn-info btn-sm\">{preds}</button>\n",
    "                <button class=\"btn btn-sm feedback-btn\" data-prediction-id=\"{prediction_id}\" \n",
    "                        data-bs-toggle=\"tooltip\" data-bs-placement=\"top\" title=\"Flag incorrect label\"\n",
    "                        style=\"background: none; border: none; color: #dc3545; padding: 2px 0 0 8px; margin-left: 5px;\">\n",
    "                    {FLAG_SVG}\n",
    "                </button>\n",
    "            </div>\n",
    "            '''\n",
    "            \n",
    "            return result_html\n",
    "    \n",
    "    return '<a href=\"#\" class=\"badge badge-warning\">Warning</a>'\n",
    "```\n",
    "\n",
    "1.  Add Feedback Route to Handle User Feedback\n",
    "\n",
    "``` python\n",
    "@app.route('/feedback', methods=['POST'])\n",
    "def feedback():\n",
    "    \"\"\"Handle user feedback about predictions\"\"\"\n",
    "    data = request.json\n",
    "    prediction_id = data.get('prediction_id')\n",
    "    \n",
    "    # Get the prediction data\n",
    "    pred_data = current_predictions[prediction_id]\n",
    "    \n",
    "    # Create user feedback task\n",
    "    task_id = create_user_feedback_task(\n",
    "        fs,\n",
    "        image_url=pred_data[\"image_url\"],\n",
    "        predicted_class=pred_data[\"prediction\"],\n",
    "        confidence=pred_data[\"confidence\"],\n",
    "        filename=pred_data[\"filename\"]\n",
    "    )\n",
    "    \n",
    "    # Return response\n",
    "    return jsonify({\n",
    "        \"success\": True,\n",
    "        \"message\": \"Thank you for your feedback!\"\n",
    "    })\n",
    "```\n",
    "\n",
    "1.  Update Frontend Files and rebuild the Flask container\n",
    "\n",
    "``` bash\n",
    "# Copying front end files into our flask container to update the UI to include feedback\n",
    "cp /home/cc/eval-loop-chi/frontend/feedback_v1/templates/index.html /home/cc/eval-loop-chi/gourmetgram/templates/index.html\n",
    "cp /home/cc/eval-loop-chi/frontend/feedback_v1/templates/base.html /home/cc/eval-loop-chi/gourmetgram/templates/base.html\n",
    "\n",
    "cp /home/cc/eval-loop-chi/frontend/feedback_v1/static/js/main.js /home/cc/eval-loop-chi/gourmetgram/static/js/main.js\n",
    "cp /home/cc/eval-loop-chi/frontend/feedback_v1/static/css/main.css /home/cc/eval-loop-chi/gourmetgram/static/css/main.css\n",
    "\n",
    "mkdir -p /home/cc/eval-loop-chi/gourmetgram/images/\n",
    "cp /home/cc/eval-loop-chi/images/flag-icon.svg /home/cc/eval-loop-chi/gourmetgram/images\n",
    "```\n",
    "\n",
    "``` bash\n",
    "docker-compose -f /home/cc/eval-loop-chi/docker/docker-compose-feedback.yaml up flask --build\n",
    "```\n",
    "\n",
    "1.  Set up Label Studio Sync CRON Job for User feedback and run it once on demand\n",
    "\n",
    "``` bash\n",
    "(crontab -l 2>/dev/null; echo '0 * * * * docker exec <label_studio_container_id> python3 /label-studio/sync_script.py 3') | crontab -\n",
    "```\n",
    "\n",
    "``` bash\n",
    "docker exec <label_studio_container_id> python3 /label-studio/sync_script.py 3\n",
    "```\n",
    "\n",
    "#### Testing the Feedback Loop\n",
    "\n",
    "1.  Go to http://{public-node-ip}:5000.\n",
    "2.  Upload images present in data/userfeedback/ folder.\n",
    "3.  Provide negative feedback for the prediction\n",
    "4.  Wait for Label Studio to Sync and go to http://{public-node-ip}:8080 and login to see the tasks created by user feedback tasks. Complete the user feedback tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve collected labeled data from human annotators in Label Studio, we need to process these annotations and organize them for model retraining. The labeled data is currently stored in the /labelstudio/output/ path in our MinIO storage system.\n",
    "\n",
    "Make sure you’ve finished the tasks in the Label Studio. To process these annotations and create properly organized training data, run:\n",
    "\n",
    "``` bash\n",
    "docker exec <label_studio_container_id> python3 /label-studio/sync_script.py \n",
    "docker exec <label_studio_container_id> python3 /label-studio/process_outputs.py\n",
    "```\n",
    "\n",
    "This script:\n",
    "\n",
    "-   Synchronizes results by sending output tasks to the respective folders in `labelstudio` bucket\n",
    "-   Extracts the human-verified labels from the annotation results\n",
    "-   Retrieves the corresponding images from our production storage\n",
    "-   Organizes these images into class-specific buckets based on their corrected labels\n",
    "-   Creates a structured dataset ready for model retraining\n",
    "-   Maintains separate tracking for annotations from different feedback sources (random sampling, user feedback, and low confidence predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get explicit labels from users"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python"
  }
 }
}
